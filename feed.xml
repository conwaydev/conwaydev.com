<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Justin Conway Chicago-based Front End Developer</title>
    <description>Justin Conway is a Chicago-based Front End Developer passionate about the web and pork.
</description>
    <link>http://conwaydev.com/</link>
    <atom:link href="http://conwaydev.com/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Sat, 14 Jul 2018 05:36:01 +0000</pubDate>
    <lastBuildDate>Sat, 14 Jul 2018 05:36:01 +0000</lastBuildDate>
    <generator>Jekyll v3.3.1</generator>
    
      <item>
        <title>Why Greenhouse Rules</title>
        <description>&lt;p&gt;&lt;img class=&quot;b-lazy&quot; src=&quot;data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==&quot; data-src=&quot;https://dha4w82d62smt.cloudfront.net/items/2A0q1K0E2o0z1g1x2W1g/Screen%20Shot%202018-07-14%20at%2012.02.08%20AM.png&quot; alt=&quot;Greenhouse.io&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Greenhouse is an applicant tracking system and recruiting software designed to optimize your entire recruiting process. Find better candidates, conduct more focused interviews, and make data-driven hiring decisions.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Sometimes I think that hiring software is a super saturated market. I see companies like Lever, Jazz, Yello, and hundreds of others in the space and I can’t help but think “Why would you try to start to a recruiting software company?”. Granted all of the companies mentioned do an excellent job and serve the needs of their customers, but I want to speak from a developers point of view as to why I feel like Greenhouse is the best.&lt;/p&gt;

&lt;h2 id=&quot;1-their-api-docs-are-awesome&quot;&gt;1. Their API docs are awesome&lt;/h2&gt;

&lt;p&gt;As a developer working with any third party service you’ll know that not all services keep an up to date docs, if they even have docs at all. Greenhouse are utilizing a generator called &lt;a href=&quot;https://github.com/lord/slate&quot;&gt;Slate&lt;/a&gt; that just looks fantastic and above all helps me find exactly what I’m looking for. You can find Greenhouse’s docs &lt;a href=&quot;https://developers.greenhouse.io/job-board.html&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;b-lazy&quot; src=&quot;data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==&quot; data-src=&quot;https://dha4w82d62smt.cloudfront.net/items/2b1k20270v0l2I1F112h/Screen%20Shot%202018-07-14%20at%2012.01.43%20AM.png&quot; alt=&quot;Greenhouse.io API docs&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;2-you-can-just-use-their-job-board-api-anywhere&quot;&gt;2. You can just use their Job Board API anywhere&lt;/h2&gt;

&lt;p&gt;This to me is the kicker, in that their Job Board API allows for a fully customizable experience. Before getting the chance to use Greenhouse, I had been working on customizing &lt;a href=&quot;https://www.jazzhr.com/&quot;&gt;JazzHR&lt;/a&gt; career pages. Now JazzHR has a wonderful backend and a great administrative experience, but at the end of the day you’re adding CSS to their templates they’ve already made, not allowing any customization. With Greenhouse’s free-for-all Job Board API you can create a specific job board experience tailored to your company. With a company like Sprout Social who truly value the candidate experience, it was a must have to not necessary have a stock approach like companies such as JazzHR and Lever.&lt;/p&gt;

&lt;p&gt;Another big side of their open-ended API is that prototyping is actually a possibility. Here’s an example of something I was able to whip up in minutes without it needing to live in our code base to show an experience where a user can filter jobs by location. This may also be a good time to mention that Sprout Social is &lt;a href=&quot;https://sproutsocial.com/careers/open-positions/#/&quot;&gt;hiring&lt;/a&gt;!&lt;/p&gt;

&lt;p data-height=&quot;265&quot; data-theme-id=&quot;dark&quot; data-slug-hash=&quot;aYZvLg&quot; data-default-tab=&quot;result&quot; data-user=&quot;conwaydev&quot; data-embed-version=&quot;2&quot; data-pen-title=&quot;Sprout Social Open Positions Filter&quot; data-preview=&quot;true&quot; class=&quot;codepen&quot;&gt;See the Pen &lt;a href=&quot;https://codepen.io/conwaydev/pen/aYZvLg/&quot;&gt;Sprout Social Open Positions Filter&lt;/a&gt; by Justin Conway (&lt;a href=&quot;https://codepen.io/conwaydev&quot;&gt;@conwaydev&lt;/a&gt;) on &lt;a href=&quot;https://codepen.io&quot;&gt;CodePen&lt;/a&gt;.&lt;/p&gt;
&lt;script async=&quot;&quot; src=&quot;https://static.codepen.io/assets/embed/ei.js&quot;&gt;&lt;/script&gt;

&lt;p&gt;The ability to simply show a list of jobs and their attributes on any web property is a super useful feature. All that said I think that Greenhouse have done a wonderful job with the ability of customization and creating solid API docs to help developers build out awesome experiences.&lt;/p&gt;
</description>
        <pubDate>Fri, 13 Jul 2018 21:50:24 +0000</pubDate>
        <link>http://conwaydev.com/blog/2018/07/13/greenhouse.html</link>
        <guid isPermaLink="true">http://conwaydev.com/blog/2018/07/13/greenhouse.html</guid>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>Performance Testing Tools</title>
        <description>&lt;p&gt;Its hard to find web developers in 2017 who don’t factor in performance into their day to day work. Stakeholders are realizing that web performance is essential to their business and conversions, and developers are realizing that not everyone in the world is accessing websites from a brand new MacBook Pro with blazing fast internet speeds. As a developer I may go a bit overboard, some may even call it an obsession, but web performance is something I’m incredibly passionate about. It all ties back in to the inclusion of the web, and providing the best possible experience for every person to access your site or product.&lt;/p&gt;

&lt;p&gt;I’d like to take this time to showcase 3 different tools I like to use for testing out the performance of whatever I’m working on at any given time. There are tons of various tools and software applications, but I like to use a range of tools to get a common baseline. Creating real world performance metrics is difficult and often inconsistent, but by using different tools you can at least get an idea of what you’re doing right, and what you may be doing wrong.&lt;/p&gt;

&lt;h3 id=&quot;webpagetestorg&quot;&gt;WebPageTest.org&lt;/h3&gt;

&lt;p&gt;&lt;img class=&quot;b-lazy&quot; src=&quot;data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==&quot; data-src=&quot;/assets/img/webpage.jpg|/assets/img/webpage@2x.jpg&quot; alt=&quot;WebPageTest.org&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.webpagetest.org/&quot;&gt;WebPageTest.org&lt;/a&gt; is easily the best (free) performance tool I’ve used. The testing is so thorough and the biggest thing that I appreciate is that they have an API, so you can programmatically run performance tests, allowing for awesome tooling like &lt;a href=&quot;https://speedtracker.org/&quot;&gt;speedtracker.org&lt;/a&gt;. There are also forums filled with really intelligent people who know way more than me about web performance. I personally like to use the visual comparison tool when I am creating a new feature in order to test performance against the current production environment, just in case I’m introducing any new performance regressions.&lt;/p&gt;

&lt;h3 id=&quot;gtmetrixcom&quot;&gt;GTMetrix.com&lt;/h3&gt;

&lt;p&gt;&lt;img class=&quot;b-lazy&quot; src=&quot;data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==&quot; data-src=&quot;/assets/img/gtmetrix.jpg|/assets/img/gtmetrix@2x.jpg&quot; alt=&quot;GTMetrix.com&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://gtmetrix.com/&quot;&gt;GTMetrix&lt;/a&gt; was actually my first introduction to web performance testing. There was a time when I worked for a small web agency and when pitching jobs to clients, things like performance or accessibility weren’t part of the scope, often times it was “How can we get this in the hands to our client as fast and cheap as possible”. I didn’t know any better, but at that time I started getting the hunch that maybe putting 40 different JavaScript files on a page wasn’t such a great idea. My coworker recommended me this tool that showed you “everything you were doing wrong with web development”. It quickly becoming my bargaining chip. I was able to show stakeholders, and eventually clients an actual number indicating that performance was something we needed to consider up front, not after the fact. I still rely heavily on GTMetrix, I really appreciate their comparison report, and also their merging of both PageSpeed scores and YSlow. Its very validating when working on a larger scale application to score high on it.&lt;/p&gt;

&lt;h3 id=&quot;google-pagespeed-insights&quot;&gt;Google PageSpeed Insights&lt;/h3&gt;

&lt;p&gt;&lt;img class=&quot;b-lazy&quot; src=&quot;data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==&quot; data-src=&quot;/assets/img/pagespeed.jpg|/assets/img/pagespeed@2x.jpg&quot; alt=&quot;Google PageSpeed Insights&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The last tool I’d like to share is Google’s own &lt;a href=&quot;https://developers.google.com/speed/pagespeed/insights/&quot;&gt;PageSpeed Insights&lt;/a&gt;. The irony of using this tool is running through various Google sites and services and seeing that not even they can get a perfect 100. I believe that their goal is raise awareness and just because you’re a Google product doesn’t mean that you can get away with bad performance. This one will always drive me nuts, but often a great tool to share with colleagues, particularly in SEO who may not be factoring in performance as to why their search results are what they are.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;There are plenty of options, such as &lt;a href=&quot;https://speedcurve.com/&quot;&gt;speedcurve.com&lt;/a&gt; or the ones listed in the comment section of &lt;a href=&quot;https://css-tricks.com/performance-tools/&quot;&gt;this CSSTricks article&lt;/a&gt;. The bottom line is that creating performant web pages and applications isn’t going anywhere. Optimizing images, only loading what we need, and relying on smarter browser caching techniques is very important, and these tools are quick to call out when you’re not. We as developers have a responsibility to ship users the best possible experiences in the most efficient ways, hopefully these tools can help you achieve that!&lt;/p&gt;
</description>
        <pubDate>Wed, 26 Apr 2017 21:50:24 +0000</pubDate>
        <link>http://conwaydev.com/blog/2017/04/26/performance-testing-tools.html</link>
        <guid isPermaLink="true">http://conwaydev.com/blog/2017/04/26/performance-testing-tools.html</guid>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>2 Awesome Uses for Screaming Frog</title>
        <description>&lt;p&gt;Recently I’ve had to learn a &lt;em&gt;lot&lt;/em&gt; about SEO in a very short amount of time. I would say the biggest “gotcha” moment I’ve had is finding out about and using the &lt;a href=&quot;https://www.screamingfrog.co.uk/seo-spider/&quot;&gt;Screaming Frog SEO Spider&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;b-lazy&quot; src=&quot;data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==&quot; data-src=&quot;/assets/img/screamingfrog.jpg&quot; alt=&quot;Screaming Frog SEO Spider&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;The Screaming Frog SEO Spider is a website crawler, that allows you to crawl websites’ URLs and fetch key onsite elements to analyse from an SEO perspective. Download for free, or purchase a licence for additional features.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;iframe width=&quot;917&quot; height=&quot;516&quot; src=&quot;https://www.youtube.com/embed/AOzOffh9HIE&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;I have been totally blown away by how you can just scan a whole site in a matter of seconds and see immediately all your broken links and image references. I spent a great portion of my web development career believing that SEO was snake oil sales, but I’m realizing its importance now more than ever &lt;sup&gt;1&lt;/sup&gt;.&lt;/p&gt;

&lt;p&gt;Screaming Frog rules for performing an SEO audit on your site, but I’d like to point out 2 interesting ways to use Screaming Frog.&lt;/p&gt;

&lt;h3 id=&quot;1-identifying-slow-loading-pages&quot;&gt;1. Identifying Slow Loading Pages&lt;/h3&gt;

&lt;p&gt;Well of course you’re an incredible web developer who is the Michael Jordan of web page performance and you never have any slow loading pages ever, right? Well if for some reason you &lt;em&gt;might&lt;/em&gt; have some slow pages Screaming Frog can identify those immediately.&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;b-lazy&quot; src=&quot;data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==&quot; data-src=&quot;/assets/img/response-time.jpg&quot; alt=&quot;Screaming Frog SEO Spider Response Times&quot; /&gt;&lt;/p&gt;

&lt;p&gt;All you need to do is filter by “Response Time” in the main crawl!&lt;/p&gt;

&lt;h3 id=&quot;2-finding-all-lazy-loaded-images&quot;&gt;2. Finding All Lazy Loaded Images&lt;/h3&gt;

&lt;p&gt;By default Screaming Frog is really awesome with images. If it finds it in your markup it will automatically make a request for that image, which rules! Now how about if you’re a radical web developer who lazy loads all their images so that their users don’t have to unnecessarily download each one &lt;sup&gt;2&lt;/sup&gt;? Well you’re in luck because theres a special part of Screaming Frog called “Custom Extractions”. All you need to do is add either an XPath or a regex for your images like so:&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;b-lazy&quot; src=&quot;data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==&quot; data-src=&quot;/assets/img/extraction.jpg&quot; alt=&quot;Screaming Frog SEO Spider Custom Extraction&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Then we can see that we got all the images on the page, even though those were already lazy loaded:&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;b-lazy&quot; src=&quot;data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==&quot; data-src=&quot;/assets/img/extraction-success.jpg&quot; alt=&quot;Screaming Frog SEO Spider Custom Extraction Success&quot; /&gt;&lt;/p&gt;

&lt;p&gt;I didn’t really understand XPath (I still don’t), but I find its easiest to get the global images by simply placing &lt;code class=&quot;highlighter-rouge&quot;&gt;//img&lt;/code&gt;. Its even easier to get the value through regex, but this will suffice for most cases.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Say what you will about Screaming Frog, it’s Windows 98-esque UI, or the fact that it probably should be a web app that has a SaaS model, it is an incredibly powerful application that definitely has changed the way I view SEO. There is so much more that you can do with the application, but its an essential tool in performing a real SEO audit of your webite.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Footnotes&lt;/em&gt;:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Caveat, there’s still totally snake oil salesmen in that industry.&lt;/li&gt;
  &lt;li&gt;Lol not me on this site.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.seerinteractive.com/blog/screaming-frog-guide/&quot;&gt;seerinteractive.com/blog/screaming-frog-guide/&lt;/a&gt; is the best link ever and explains 53 cooler things to do with the software.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.screamingfrog.co.uk/10-features/&quot;&gt;https://www.screamingfrog.co.uk/10-features/&lt;/a&gt; is also a great list of ways to use the software and actually from the company that develops and maintains it.&lt;/li&gt;
&lt;/ol&gt;
</description>
        <pubDate>Tue, 23 Aug 2016 21:50:24 +0000</pubDate>
        <link>http://conwaydev.com/blog/2016/08/23/screamingfrog-seo-tool.html</link>
        <guid isPermaLink="true">http://conwaydev.com/blog/2016/08/23/screamingfrog-seo-tool.html</guid>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>Using Gulp in a Jekyll Project</title>
        <description>&lt;p&gt;Even though I’m trying not to rely on JS build systems as much anymore and rather use plain npm scripts, I have to say I still love them. They absolutely changed my life when I started using them. Today I’m going to talk about using Gulp inside of Jekyll. Now Jekyll has a really useful server inside itself, but I prefer being able to control a little more and gulp gives me that ability.&lt;/p&gt;

&lt;h4 id=&quot;what-is-gulp&quot;&gt;What is gulp?&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/gulp.jpg&quot; alt=&quot;gulp&quot; /&gt;&lt;/p&gt;

&lt;p&gt;From https://github.com/gulpjs/gulp it is described as:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Automation - gulp is a toolkit that helps you automate painful or time-consuming tasks in your development workflow.&lt;/li&gt;
  &lt;li&gt;Platform-agnostic - Integrations are built into all major IDEs and people are using gulp with PHP, .NET, Node.js, Java, and other platforms.&lt;/li&gt;
  &lt;li&gt;Strong Ecosystem - Use npm modules to do anything you want + over 2000 curated plugins for streaming file transformations&lt;/li&gt;
  &lt;li&gt;Simple - By providing only a minimal API surface, gulp is easy to learn and simple to use&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I like to use gulp to compile and concatenate my assets, but there is so much you can do with it. The first thing you’re going to want to do is create your package.json file. I find the easiest way is to &lt;code class=&quot;highlighter-rouge&quot;&gt;npm init&lt;/code&gt;. Once you’ve generated that you can go ahead and start installing our dependencies we’re going to need.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;npm install gulp gulp-sass browser-sync gulp-autoprefixer gulp-plumber --save-dev
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Then you’re going to create a file called &lt;code class=&quot;highlighter-rouge&quot;&gt;gulpfile.js&lt;/code&gt; and paste this code in there.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;var gulp = require('gulp');
var sass = require('gulp-sass');
var browserSync = require('browser-sync');
var prefix = require('gulp-autoprefixer');
var minify = require('gulp-clean-css');
var plumber = require('gulp-plumber');
var cp = require('child_process');

gulp.task('jekyll-build', function (done) {
    return cp.spawn('jekyll' , ['build'], {stdio: 'inherit'})
        .on('close', done);
});

gulp.task('jekyll-rebuild', ['jekyll-build'], function () {
    browserSync.reload();
});

gulp.task('browser-sync', ['sass', 'jekyll-build'], function() {
    browserSync({
        server: {
            baseDir: '_site'
        }
    });
});

gulp.task('sass', function(){
    return gulp.src('_sass/main.scss')
        .pipe(sass())
        .pipe(prefix('last 2 versions'))
        .pipe(minify())
        .pipe(gulp.dest('_site/css'))
        .pipe(browserSync.reload({stream:true}))
        .pipe(gulp.dest('css'))
        .pipe(plumber())
});

gulp.task('watch', function () {
    gulp.watch(['*.scss', 'css/*.scss', '_sass/**/*.scss'], ['sass', 'jekyll-rebuild']);
    gulp.watch(['*.html', '_layouts/*.html', '_includes/*.html', '_posts/*'], ['jekyll-rebuild']);
});

gulp.task('default', ['browser-sync', 'watch']);

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;You can see that what we’re doing is instead of letting &lt;code class=&quot;highlighter-rouge&quot;&gt;jekyll serve&lt;/code&gt; handle the SCSS we are just compiling it ourselves then running &lt;code class=&quot;highlighter-rouge&quot;&gt;jekyll rebuild&lt;/code&gt;. So once you have your &lt;code class=&quot;highlighter-rouge&quot;&gt;gulpfile.js&lt;/code&gt; filled with this all you need to do is run &lt;code class=&quot;highlighter-rouge&quot;&gt;gulp&lt;/code&gt; and it will automatically spin up a live server and minify your SCSS. Neat!&lt;/p&gt;
</description>
        <pubDate>Sat, 21 May 2016 03:50:24 +0000</pubDate>
        <link>http://conwaydev.com/blog/2016/05/21/using-gulp.html</link>
        <guid isPermaLink="true">http://conwaydev.com/blog/2016/05/21/using-gulp.html</guid>
        
        
        <category>blog</category>
        
      </item>
    
  </channel>
</rss>
